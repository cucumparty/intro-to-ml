{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Random Forest Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы дошли до этой точки, поздравляю, вы уже на полпути к успешному решению домашнего задания!\n",
    "\n",
    "Итак, начнем..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,mean_absolute_error,mean_squared_error,r2_score,make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №1:  Загрузите и обработайте данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно само задание:\n",
    "1) Постройте гистограмму распределения данных по классам\n",
    "2) Постройте boxplot по фичам, для того чтобы увидеть распределение признаков\n",
    "3) Постройте heatmap корреляции признаков с помощью seaborn\n",
    "\n",
    "В каждом пункте сделайте выводы относительно полученных графиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По традиции начнем с невероятной истории:\n",
    "\n",
    "Фрэнсис Гальтон в 1906 году посетил рынок, где проводилась некая лотерея для крестьян. \n",
    "Их собралось около 800 человек, и они пытались угадать вес быка, который стоял перед ними. Бык весил 1198 фунтов. Ни один крестьянин не угадал точный вес быка, но если посчитать среднее от их предсказаний, то получим 1197 фунтов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1198bull](./sources/bull.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод бутстрэпа заключается в следующем. Пусть имеется выборка $\\large X$ размера $\\large N$. Равномерно возьмем из выборки $\\large N$ объектов с возвращением. Это означает, что мы будем $\\large N$ раз выбирать произвольный объект выборки (считаем, что каждый объект «достается» с одинаковой вероятностью $\\large \\frac{1}{N}$), причем каждый раз мы выбираем из всех исходных $\\large N$ объектов. Можно представить себе мешок, из которого достают шарики: выбранный на каком-то шаге шарик возвращается обратно в мешок, и следующий выбор опять делается равновероятно из того же числа шариков. Отметим, что из-за возвращения среди них окажутся повторы. Обозначим новую выборку через $\\large X_1$. Повторяя процедуру $\\large M$ раз, сгенерируем $\\large M$ подвыборок $\\large X_1, \\dots, X_M$. Теперь мы имеем достаточно большое число выборок и можем оценивать различные статистики исходного распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bootstrap](./sources/bootstrap.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №2: Реализуйте функцию бутстрепа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bootstraps(data, n_samples):\n",
    "    \"\"\"\n",
    "    Generates bootstrap samples for given data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array of type float with shape (n_datapoints, n_features)\n",
    "           Dataset\n",
    "           \n",
    "    n_samples : int\n",
    "                Count of bootstrap samples\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with n_samples bootstrap samples\n",
    "    \"\"\"\n",
    "    bootstrap = {}\n",
    "    sample_size = data.shape[0]\n",
    "    indices = [i for i in range(sample_size)]\n",
    "\n",
    "    for sample in range(n_samples):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        bootstrap[\"tree_\" + str(sample)] = {'train': train_sample, 'test': test_sample}\n",
    "\n",
    "    return bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как функция реализована, проверьте, что бутстреп реализован правильно: \n",
    "1) Сгенерируйте выборку из стандартного нормального распределения размера 30\n",
    "2) Сделайте 1000 бутстреп выборок с помощью функции make_bootstrap и найдите среднее значение в каждой из них\n",
    "3) На основании полученных 1000 средних постройте гистограмму\n",
    "4) Постройте на этом же графике функцию плотности стандартного нормального распределения\n",
    "\n",
    "Тест пройден успешно, если гистограмма приближает столбиками функцию плотности\n",
    "\n",
    "P. S. В статистике принято выбирать количество бинов на гистограмме как $ log_{2}(n) $, где n размер выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-bag error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поясним, зачем в примере выше нужна тестовая выборка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забегая вперед, отметим, что при использовании случайных лесов нет необходимости в кросс-валидации или в отдельном тестовом наборе, чтобы получить несмещенную оценку ошибки набора тестов. Посмотрим, как получается \"внутренняя\" оценка модели во время ее обучения.\n",
    "\n",
    "Каждое дерево строится с использованием разных образцов бутстрэпа из исходных данных. Примерно 37% примеров остаются вне выборки бутстрэпа и не используются при построении k-го дерева.\n",
    "\n",
    "Это можно легко доказать: пусть в выборке $\\large \\ell$ объектов. На каждом шаге все объекты попадают в подвыборку с возвращением равновероятно, т.е отдельный объект — с вероятностью $\\large\\frac{1}{\\ell}.$ Вероятность того, что объект НЕ попадет в подвыборку (т.е. его не взяли $\\large \\ell$ раз): $\\large (1 - \\frac{1}{\\ell})^\\ell$. При $\\large \\ell \\rightarrow +\\infty$ получаем один из \"замечательных\" пределов $\\large \\frac{1}{e}$. Тогда вероятность попадания конкретного объекта в подвыборку $\\large \\approx 1 - \\frac{1}{e} \\approx 63\\%$.\n",
    "\n",
    "Давайте рассмотрим, как это работает на практике:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![oobe](./sources/oobe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке изображена оценка oob-ошибки. Верхний рисунок – это наша исходная выборка, ее мы делим на обучающую(слева) и тестовую(справа). На рисунке слева у нас есть сетка из квадратиков, которая идеально разбивает нашу выборку. Теперь нужно оценить долю верных ответов на нашей тестовой выборке. На рисунке видно, что наш классификатор ошибся в 4 наблюдениях, которые мы не использовали для обучения. Значит, доля верных ответов нашего классификатора: $\\large \\frac{11}{15}*100\\% = 73.33\\%$\n",
    "\n",
    "Получается, что каждый базовый алгоритм обучается на ~63% исходных объектов. Значит, на оставшихся ~37% его можно сразу проверять. Out-of-Bag оценка — это усредненная оценка базовых алгоритмов на тех ~37% данных, на которых они не обучались."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лео Брейман нашел применение бутстрэпу не только в статистике, но и в машинном обучении. Он вместе с Адель Катлер усовершенстовал алгоритм случайного леса, предложенный Хо, добавив к первоначальному варианту построение некоррелируемых деревьев на основе CART, в сочетании с методом случайных подпространств и бэггинга.\n",
    "\n",
    "Решающие деревья являются хорошим семейством базовых классификаторов для бэггинга, поскольку они достаточно сложны и могут достигать нулевой ошибки на любой выборке. Метод случайных подпространств позволяет снизить коррелированность между деревьями и избежать переобучения. Базовые алгоритмы обучаются на различных подмножествах признакового описания, которые также выделяются случайным образом.\n",
    "Ансамбль моделей, использующих метод случайного подпространства, можно построить, используя следующий алгоритм:\n",
    "\n",
    "1) Пусть количество объектов для обучения равно $\\large N$, а количество признаков $\\large D$.\n",
    "2) Выберите $\\large L$ как число отдельных моделей в ансамбле.\n",
    "3) Для каждой отдельной модели $\\large l$ выберите $\\large dl (dl < D) $ как число признаков для $\\large l$. Обычно для всех моделей используется только одно значение $\\large dl$.\n",
    "4) Для каждой отдельной модели $\\large l$ создайте обучающую выборку, выбрав $\\large dl$ признаков из $\\large D$, и обучите модель.\n",
    "5) Теперь, чтобы применить модель ансамбля к новому объекту, объедините результаты отдельных $\\large L$ моделей мажоритарным голосованием или путем комбинирования апостериорных вероятностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм построения случайного леса, состоящего из $\\large N$ деревьев, выглядит следующим образом:\n",
    "\n",
    "- Для каждого $\\large n = 1, \\dots, N$:\n",
    "     - Сгенерировать выборку $\\large X_n$ с помощью бутстрэпа;\n",
    "     - Построить решающее дерево $\\large b_n$ по выборке $\\large X_n$:\n",
    "         - по заданному критерию мы выбираем лучший признак, делаем разбиение в дереве по нему и так до исчерпания выборки\n",
    "         - дерево строится, пока в каждом листе не более $\\large n_\\text{min}$ объектов или пока не достигнем определенной высоты дерева\n",
    "         - при каждом разбиении сначала выбирается $\\large m$ случайных признаков из $\\large n$ исходных, и оптимальное разделение выборки ищется только среди них.\n",
    "\n",
    "Итоговый классификатор $\\large a(x) = \\frac{1}{N}\\sum_{i = 1}^N b_i(x)$, простыми словами — для задачи кассификации мы выбираем решение голосованием по большинству, а в задаче регрессии — средним.\n",
    "\n",
    "Рекомендуется в задачах классификации брать $\\large m = \\sqrt{n}$, а в задачах регрессии — $\\large m = \\frac{n}{3}$, где $\\large n$ — число признаков. Также рекомендуется в задачах классификации строить каждое дерево до тех пор, пока в каждом листе не окажется по одному объекту, а в задачах регрессии — пока в каждом листе не окажется по пять объектов.\n",
    "\n",
    "Таким образом, случайный лес — это бэггинг над решающими деревьями, при обучении которых для каждого разбиения признаки выбираются из некоторого случайного подмножества признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №3: Допишите классы в модуле forest (workdir/forest/forest.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что папки в контейнере и на компьютере синхронизированы, а это значит, что вы можете открыть модуль в любом удобном IDE на компьютере и все изменения тут же произойдут в контейнере.\n",
    "\n",
    "Задание:\n",
    "1) Допишите недостающий код в workdir/forest/forest.py\n",
    "3) Сравните accuracy/precision/recall с имплементацией из библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AwesomeTester\n",
    "from forest.forest import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(balance_class_weights=True)\n",
    "forest.fit(X.values, y.values, print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {'accuracy': make_scorer(accuracy_score), \n",
    "                   'precision': make_scorer(precision_score, average='weighted'),\n",
    "                   'recall': make_scorer(recall_score, average='weighted')}\n",
    "scores        = cross_validate(forest, X.values, y.values, cv=StratifiedKFold(10), scoring=scoring_metrics)\n",
    "\n",
    "if (AwesomeTester.magic(np.mean(scores['test_accuracy']))):\n",
    "    print(\"Congratulations!\")\n",
    "else:\n",
    "    print(\"Oooooops... Something went wrong :(\")\n",
    "\n",
    "# CHECK ACCURACY, PRECISION AND RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
